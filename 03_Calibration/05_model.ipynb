{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f4016f-87bd-41dd-90eb-e92afe20fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "sns.set_theme(style='white', context='notebook', font_scale=1.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcec38db-a532-4a6f-aa3b-b64522e11210",
   "metadata": {},
   "source": [
    "## Section 1: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5721451e-7a2d-482d-82ef-97097153831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1pl:  -13583.776 | -13575.166 | 1073.293 | 161.265\n",
      "2pl:  -13494.605 | -13561.354 | 917.542 | 248.556\n",
      "3pl:  -13506.159 | -13360.679 | 899.248 | 262.784\n"
     ]
    }
   ],
   "source": [
    "for m in ['1pl','2pl','3pl']:\n",
    "    \n",
    "    ## Load ppc.\n",
    "    ppc = read_csv(os.path.join('stan_results', f'{m}_ppc.csv'))\n",
    "        \n",
    "    ## Model comparison.\n",
    "    louo = ppc.louo.sum()\n",
    "    loco = ppc.groupby('subject').loco.mean().sum()\n",
    "    pwaic_u = ppc.pwaic_u.sum()\n",
    "    pwaic_c = ppc.groupby('subject').pwaic_c.mean().sum()\n",
    "    \n",
    "    print('%s:  %0.3f | %0.3f | %0.3f | %0.3f' %(m, louo, loco, pwaic_u, pwaic_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906fb18a-482d-410f-981e-26f476aa206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m2pl - m1pl: 13.812 (10.439)\n",
      "m3pl - m1pl: 214.487 (21.478)\n",
      "m3pl - m2pl: 200.675 (15.601)\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "for a, b in list(combinations(['1pl','2pl','3pl'], 2)):\n",
    "    \n",
    "    ## Load data.\n",
    "    df1 = read_csv(os.path.join('stan_results', f'{a}_ppc.csv'))\n",
    "    df2 = read_csv(os.path.join('stan_results', f'{b}_ppc.csv'))\n",
    "    \n",
    "    arr = df2.groupby('subject').loco.mean() - df1.groupby('subject').loco.mean()\n",
    "    \n",
    "    ## Compute stats.\n",
    "    N = df1.subject.nunique()\n",
    "    mu = np.sum(arr)\n",
    "    se = np.std(arr) * np.sqrt(N)\n",
    "    \n",
    "    print(f'm{b} - m{a}: %0.3f (%0.3f)' %(mu, se))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b455be9-5515-4778-a958-7945b922400e",
   "metadata": {},
   "source": [
    "## variance explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea2838a1-5eb1-45b1-8859-bd7e130716ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import OLS\n",
    "\n",
    "df = read_csv('stan_results/3pl_summary.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083985dc-5d3e-4481-be68-df8918de8d8b",
   "metadata": {},
   "source": [
    "#### subject ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd23a81a-7f8e-4a1b-a176-2916dced2d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6675499384665408\n",
      "0.6563162347527295\n"
     ]
    }
   ],
   "source": [
    "rho = df.T.filter(regex='rho').T['Mean'].values\n",
    "theta = df.T.filter(regex='theta\\[').T['Mean'].values\n",
    "theta -= theta.mean()\n",
    "\n",
    "## Prepare design matrix.\n",
    "zscore = lambda x: (x - np.nanmean(x)) / np.nanstd(x)\n",
    "X1 = read_csv('designs/X1.csv').apply(zscore).fillna(0)\n",
    "X1 = X1.values\n",
    "\n",
    "mu = X1 @ rho\n",
    "mu -= mu.mean()\n",
    "\n",
    "fit = OLS(theta, mu).fit()\n",
    "print(fit.rsquared)\n",
    "print(np.sqrt(np.square(rho).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499ff63-e552-4813-b0b2-400521768826",
   "metadata": {},
   "source": [
    "#### item difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaa6a4b9-9f3e-4b47-a06b-36c469af476f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7622903956532388\n"
     ]
    }
   ],
   "source": [
    "beta_mu = df.T.filter(regex='beta_mu').T['Mean'].values\n",
    "beta = df.T.filter(regex='beta\\[').T['Mean'].values\n",
    "beta -= beta.mean()\n",
    "\n",
    "## Prepare design matrix.\n",
    "zscore = lambda x: (x - np.nanmean(x)) / np.nanstd(x)\n",
    "X2 = read_csv('designs/X2.csv').apply(zscore).fillna(1)\n",
    "X2 = X2.values\n",
    "\n",
    "mu = X2[:,1:] @ beta_mu[1:]\n",
    "mu -= mu.mean()\n",
    "\n",
    "fit = OLS(beta, mu).fit()\n",
    "print(fit.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ae770-9a1d-47e7-a067-7a21fe7a1c0e",
   "metadata": {},
   "source": [
    "#### item discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6d4d03-6bd7-423d-b973-d6b7ff9ddf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8603342075425153\n"
     ]
    }
   ],
   "source": [
    "alpha_mu = df.T.filter(regex='alpha_mu').T['Mean'].values\n",
    "alpha = np.log(df.T.filter(regex='alpha\\[').T['Mean'].values)\n",
    "alpha -= alpha.mean()\n",
    "\n",
    "## Prepare design matrix.\n",
    "zscore = lambda x: (x - np.nanmean(x)) / np.nanstd(x)\n",
    "X2 = read_csv('designs/X2.csv').apply(zscore).fillna(1)\n",
    "X2 = X2.values\n",
    "\n",
    "mu = X2[:,1:] @ alpha_mu[1:]\n",
    "mu -= mu.mean()\n",
    "\n",
    "fit = OLS(alpha, mu).fit()\n",
    "print(fit.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6d879-29b4-4498-a340-4d0f657f2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [ 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
    "       26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 39, 40, 42, 44, 45, 46, 47,\n",
    "       49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
    "       67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80]\n",
    "dif = [ 6, 18, 24, 26, 34, 47, 50, 52, 54, 61, 66, 75]\n",
    "\n",
    "hue = np.repeat(np.in1d(items, dif), 2)\n",
    "\n",
    "beta  = df.T.filter(regex='beta\\[').T['Mean'].values\n",
    "alpha = df.T.filter(regex='alpha\\[').T['Mean'].values\n",
    "ax = sns.scatterplot(x=beta, y=alpha, hue=hue)\n",
    "ax.axhline(1 / 0.75, color='0.5', linestyle='--', zorder=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026118c2-c8ab-4ead-b15f-65b7d75f53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data.\n",
    "data = read_csv(os.path.join('data', 'data.csv'))\n",
    "\n",
    "## Apply rejections.\n",
    "reject = read_csv(os.path.join('data', 'reject.csv'))\n",
    "data = data.loc[data.subject.isin(reject.query('reject==0').subject)]\n",
    "\n",
    "## Re-index items.\n",
    "data['item_id'] = data.apply(lambda x: '%0.2d' %x['item'] + '_' + x['distractor'], 1)\n",
    "\n",
    "## Score missing data.\n",
    "data['accuracy'] = data['accuracy'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7d06d-b3da-4a08-9ffe-3d072127f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import OLS\n",
    "\n",
    "y = data.groupby('item_id').rt.mean().values\n",
    "X = np.column_stack([np.ones_like(beta), zscore(beta), zscore(alpha)])\n",
    "\n",
    "\n",
    "fit = OLS(y, X).fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf7d67-b80d-43ea-866d-f9c5c5f5cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import OLS\n",
    "\n",
    "y = np.log(alpha)\n",
    "x = zscore(data.groupby('item_id').rt.mean().values)\n",
    "X = np.column_stack([np.ones_like(beta), x, x**2])\n",
    "\n",
    "\n",
    "fit = OLS(y, X).fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e395c-e458-4a15-acbc-38690648607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = read_csv('designs/X2.csv')\n",
    "X2['rt'] = gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b90631-86be-4609-b8b9-345411a4f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.corr().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859f886-1c5b-423d-adc6-d425fe375e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = read_csv('stan_results/3pl_ppc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3150f-ac3f-443d-a5bd-8d0575a55380",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = ppc.groupby('item_id').agg({'accuracy':'mean', 'y_hat':'mean'})\n",
    "\n",
    "ax = sns.scatterplot(x='accuracy', y='y_hat', data=gb)\n",
    "ax.plot([0.15,1],[0.15,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1ca74-559b-4629-9c3c-77a51de4c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = ppc.groupby('subject').agg({'accuracy':'sum', 'y_hat':'sum'})\n",
    "\n",
    "ax = sns.stripplot(x='accuracy', y='y_hat', data=gb, jitter=0.3, size=3)\n",
    "ax.plot([0,16],[0,16])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
